# Neural Network 0 to 1: OCR Implementation

Welcome to the **Neural Network 0 to 1: OCR Implementation** repository! This project is a comprehensive guide to building a neural network for Optical Character Recognition (OCR) from scratch. The goal is to take you through the process of developing a basic neural network and applying it to recognize handwritten digits.

**This project was developed as part of a workshop conducted under IEEE SIES GST, focusing on understanding the core principles of machine learning. The workshop covered concepts ranging from basic mathematics used in computing a neuron to classifying 10-digit numbers using a fully connected neural network.**

## Project Overview

Optical Character Recognition (OCR) is a key technology in various applications, including automated data entry, document processing, and more. In this project, you'll learn how to build a simple neural network that can read and recognize handwritten digits, akin to what you'd find in the classic MNIST dataset.

## Features

- **End-to-End Neural Network Implementation:** Starting from scratch, you'll build a neural network tailored for OCR, without relying on high-level machine learning frameworks.
- **Handwritten Digit Recognition:** The network is trained to recognize digits from the MNIST dataset, providing a practical and widely recognized use case for neural networks.
- **Detailed Walkthrough:** Each step of the network's development is thoroughly explained, making it easy to follow along and understand the underlying concepts.

## Table of Contents

1. [Usage](#usage)
2. [Project Structure](#project-structure)
3. [Understanding the Code](#understanding-the-code)
4. [Customization](#customization)
5. [Contributing](#contributing)
6. [License](#license)
7. [Acknowledgments](#acknowledgments)

## Project Structure

Here’s a breakdown of the repository’s contents:

`/data/` - Contains scripts for downloading and preparing the MNIST dataset.
`/models/` - Includes the neural network models built for OCR.
`/utils/` - Utility functions for data processing, model evaluation, and more.
`main.py` - The main script for running the training and testing processes.
`requirements.txt`- A list of dependencies required to run the project.

## Understanding the Code

### Data Preparation
The data preparation script in `/data/` handles the downloading, normalization, and formatting of the MNIST dataset. This step is crucial for ensuring the network receives input in a form it can learn from effectively.

### Neural Network Architecture
The network is a simple feedforward neural network with layers structured to gradually abstract and recognize features of the digits. You can explore the architecture details in the `/models/` directory.

### Training and Evaluation
In `main.py`, the training loop iterates through the dataset, adjusting weights using backpropagation, and evaluates the network's accuracy on unseen data.

## Customization

Want to extend the project? Here are some ideas:

Add Layers: Experiment with adding more layers or different types of layers (e.g., convolutional layers) to improve accuracy.
Different Datasets: Try applying the network to a different OCR dataset or even a completely different problem domain.
Hyperparameter Tuning:** Adjust learning rates, batch sizes, and other hyperparameters to optimize the network’s performance.

## Contributing

Contributions are welcome! Whether you have suggestions for improvement, spot a bug, or want to add new features, feel free to fork the repository and submit a pull request.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

## Acknowledgments

This project is inspired by the need to understand the inner workings of neural networks, particularly in the context of OCR. Special thanks to the Aditya Dikonda (https://github.com/Adityadikonda10 ) and educators whose work in the machine learning community made this project possible.
